{"title":"Ollama environment variable setting on Linux","uid":"6f889a3a77cacd01ccd2898ea1d00f2f","slug":"Ollama-environment-variable-setting-on-Linux","date":"2024-07-23T09:21:20.000Z","updated":"2024-09-07T11:47:51.004Z","comments":true,"path":"api/articles/Ollama-environment-variable-setting-on-Linux.json","keywords":null,"cover":"/img/202407/working.png","content":"<p><img src=\"/img/202407/working.png\"><br><strong>Ollama</strong> is a fantastic tool for running large language models. Its setup is very simple, requiring just one command on Linux.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl -fsSL https://ollama.com/install.sh | sh</span><br></pre></td></tr></table></figure>\n\n<p>However, when other services want to use Ollama, they may encounter issues relate to environment variable settings.<br>For example, by default, Ollama listens only on 127.0.0.1, which can cause problems if you need it to listen on all IPs. Fortunately, Ollama provides an environment varibale <code>OLLAMA_HOST=0.0.0.0</code> that allows it to listen on all IPs.</p>\n<p>This document records how to the environment variables I used for setting up Ollama.</p>\n<h1 id=\"Step-by-Step\"><a href=\"#Step-by-Step\" class=\"headerlink\" title=\"Step-by-Step\"></a>Step-by-Step</h1><ol>\n<li><p>After installing Ollama using the command above, you can edit systemd service by running <code>systemctl edit ollama.service</code>. This will open an editor(default to nano, but you can temporarily change it to vim using <code>export EDITOR=vim</code>).</p>\n</li>\n<li><p>For each environment variable, add a line starting with <code>Environment</code> under Section <code>[Service]</code>:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### Editing /etc/systemd/system/ollama.service.d/override.conf</span></span><br><span class=\"line\"><span class=\"comment\">### Anything between here and the comment below will become the new contents of the file</span></span><br><span class=\"line\"></span><br><span class=\"line\">[Service]</span><br><span class=\"line\">Environment=<span class=\"string\">&quot;OLLAMA_HOST=0.0.0.0&quot;</span></span><br><span class=\"line\">Environment=<span class=\"string\">&quot;OLLAMA_ORIGINS=chrome-extension://*&quot;</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### Lines below this comment will be discarded</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">### /etc/systemd/system/ollama.service</span></span><br><span class=\"line\"><span class=\"comment\"># [Unit]</span></span><br><span class=\"line\"><span class=\"comment\"># Description=Ollama Service</span></span><br><span class=\"line\"><span class=\"comment\"># After=network-online.target</span></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>Note that variables should be write between ‘### Anthing..’ and ‘### Lines below this comment will be discarded’. If you don’t follow this format, it won’t work (I learned this the hard way!).</p>\n</li>\n<li><p>Save the file using <code>Ctrl+O</code>, and then exit nano using <code>Ctrl+X</code>.</p>\n</li>\n<li><p>Reload <code>systemd</code> and restart Ollama:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">systemctl daemon-reload &amp;&amp; systemctl restart ollama</span><br></pre></td></tr></table></figure></li>\n</ol>\n<h1 id=\"Verification\"><a href=\"#Verification\" class=\"headerlink\" title=\"Verification\"></a>Verification</h1><p>To verify that the setup was successful, use <code>netstat -tunpl</code> to check the IP and port:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@aiserver:/home/jevoncode<span class=\"comment\"># netstat -tunpl</span></span><br><span class=\"line\">Active Internet connections (only servers)</span><br><span class=\"line\">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    </span><br><span class=\"line\">tcp6       0      0 :::11434                :::*                    LISTEN      9870/ollama  </span><br></pre></td></tr></table></figure>\n<p>If you see output like this, your setup is compalte.</p>\n","feature":true,"text":"Ollama is a fantastic tool for running large language models. Its setup is very ...","permalink":"/post/Ollama-environment-variable-setting-on-Linux","photos":[],"count_time":{"symbolsCount":"2.2k","symbolsTime":"2 mins."},"categories":[],"tags":[],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Step-by-Step\"><span class=\"toc-text\">Step-by-Step</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#Verification\"><span class=\"toc-text\">Verification</span></a></li></ol>","author":{"name":"Jevoncode","slug":"blog-author","avatar":"img/favicon.jpg","link":"/","description":"You’ve got to have models in your head and you’ve got to array you experience – both vicarious and direct – onto this latticework of mental models.","socials":{"github":"https://github.com/jevoncode","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"LLM as a Service","uid":"f682aa67763c04130b86166bc61cd4e7","slug":"llm-as-a-service","date":"2024-07-27T08:34:35.000Z","updated":"2024-09-07T11:47:54.466Z","comments":true,"path":"api/articles/llm-as-a-service.json","keywords":null,"cover":"/img/202407/202407271640.jpg","text":" LLM as a ServiceI initially published my project that utilizes LLM as a service...","permalink":"/post/llm-as-a-service","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[],"tags":[],"author":{"name":"Jevoncode","slug":"blog-author","avatar":"img/favicon.jpg","link":"/","description":"You’ve got to have models in your head and you’ve got to array you experience – both vicarious and direct – onto this latticework of mental models.","socials":{"github":"https://github.com/jevoncode","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"English Gramar - Nouns","uid":"f9325c60c551a808709264c3df1fe780","slug":"english-grammar-nouns","date":"2024-07-14T14:47:41.000Z","updated":"2024-09-07T11:48:01.090Z","comments":true,"path":"api/articles/english-grammar-nouns.json","keywords":null,"cover":null,"text":"Here are the basic elements of a sentence. You need to know about the different ...","permalink":"/post/english-grammar-nouns","photos":[],"count_time":{"symbolsCount":"6k","symbolsTime":"5 mins."},"categories":[],"tags":[{"name":"English Grammar","slug":"English-Grammar","count":1,"path":"api/tags/English-Grammar.json"}],"author":{"name":"Jevoncode","slug":"blog-author","avatar":"img/favicon.jpg","link":"/","description":"You’ve got to have models in your head and you’ve got to array you experience – both vicarious and direct – onto this latticework of mental models.","socials":{"github":"https://github.com/jevoncode","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}