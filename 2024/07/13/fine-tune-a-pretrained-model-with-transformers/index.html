

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.jpg">
  <link rel="icon" href="/img/favicon.jpg">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jevoncode">
  <meta name="keywords" content="">
  
    <meta name="description" content="My Environment CUDA 12.2 Python 3.10.12 PyTorch 2.3.1+cu121 transformers 4.42.0 datasets 2.20.0 accelerate 0.32.1 evaluate 0.4.2 scikit-learn 1.5.1  Get Familiar With DatasetsData Structureload the d">
<meta property="og:type" content="article">
<meta property="og:title" content="Fine-Tuning a Pretrained Model - A Beginner&#39;s Journey">
<meta property="og:url" content="https://jevoncode.github.io/2024/07/13/fine-tune-a-pretrained-model-with-transformers/index.html">
<meta property="og:site_name" content="Jevoncode">
<meta property="og:description" content="My Environment CUDA 12.2 Python 3.10.12 PyTorch 2.3.1+cu121 transformers 4.42.0 datasets 2.20.0 accelerate 0.32.1 evaluate 0.4.2 scikit-learn 1.5.1  Get Familiar With DatasetsData Structureload the d">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jevoncode.github.io/img/202407/202407131359.jpg">
<meta property="article:published_time" content="2024-07-13T05:47:04.000Z">
<meta property="article:modified_time" content="2024-07-13T06:00:49.140Z">
<meta property="article:author" content="Jevoncode">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://jevoncode.github.io/img/202407/202407131359.jpg">
  
  
  
  <title>Fine-Tuning a Pretrained Model - A Beginner&#39;s Journey - Jevoncode</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"jevoncode.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":"G-65YED77ZKY"},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=G-65YED77ZKY", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', 'G-65YED77ZKY');
        });
      }
    </script>
  

  

  

  

  



  
<meta name="generator" content="Hexo 7.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Jevoncode</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Fine-Tuning a Pretrained Model - A Beginner&#39;s Journey"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-07-13 13:47" pubdate>
          July 13, 2024 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          695 words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          6 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Fine-Tuning a Pretrained Model - A Beginner&#39;s Journey</h1>
            
            
              <div class="markdown-body">
                
                <p><img src="/img/202407/202407131359.jpg" srcset="/img/loading.gif" lazyload></p>
<h1 id="My-Environment"><a href="#My-Environment" class="headerlink" title="My Environment"></a>My Environment</h1><ul>
<li>CUDA 12.2</li>
<li>Python 3.10.12</li>
<li>PyTorch 2.3.1+cu121</li>
<li>transformers 4.42.0</li>
<li>datasets 2.20.0</li>
<li>accelerate 0.32.1</li>
<li>evaluate 0.4.2</li>
<li>scikit-learn 1.5.1</li>
</ul>
<h1 id="Get-Familiar-With-Datasets"><a href="#Get-Familiar-With-Datasets" class="headerlink" title="Get Familiar With Datasets"></a>Get Familiar With Datasets</h1><h2 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h2><p>load the dataset from Hugging Face and explore it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset<br>dataset = load_dataset(<span class="hljs-string">&quot;yelp_review_full&quot;</span>)<br><span class="hljs-built_in">print</span>(dataset[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">100</span>])<br><span class="hljs-built_in">print</span>(dataset[<span class="hljs-string">&quot;train&quot;</span>].shape)<br><span class="hljs-built_in">print</span>(dataset)<br></code></pre></td></tr></table></figure>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>&#x27;label&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> &#x27;text&#x27;<span class="hljs-punctuation">:</span> &#x27;My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\nThe cashier took my friends\&#x27;s order<span class="hljs-punctuation">,</span> then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\&#x27;s meal. After watching two people who ordered after me be handed their food<span class="hljs-punctuation">,</span> I asked where mine was. The manager started yelling at the cashiers for \\<span class="hljs-string">&quot;serving off their orders\\&quot;</span> when they didn\&#x27;t have their food. But neither cashier was anywhere near those controls<span class="hljs-punctuation">,</span> and the manager was the one serving food to customers and clearing the boards.\\nThe manager was rude when giving me my order. She didn\&#x27;t make sure that I had everything ON MY RECEIPT<span class="hljs-punctuation">,</span> and never even had the decency to apologize that I felt I was getting poor service.\\nI\&#x27;ve eaten at various McDonalds restaurants for over <span class="hljs-number">30</span> years. I\&#x27;ve worked at more than one location. I expect bad days<span class="hljs-punctuation">,</span> bad moods<span class="hljs-punctuation">,</span> and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!&#x27;<span class="hljs-punctuation">&#125;</span><br>```scss<br>(<span class="hljs-number">650000</span><span class="hljs-punctuation">,</span> <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs css">DatasetDict(&#123;<br>    train: <span class="hljs-built_in">Dataset</span>(&#123;<br>        features: [<span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;text&#x27;</span>],<br>        num_rows: <span class="hljs-number">650000</span><br>    &#125;)<br>    test: <span class="hljs-built_in">Dataset</span>(&#123;<br>        features: [<span class="hljs-string">&#x27;label&#x27;</span>, <span class="hljs-string">&#x27;text&#x27;</span>],<br>        num_rows: <span class="hljs-number">50000</span><br>    &#125;)<br>&#125;)<br></code></pre></td></tr></table></figure>
<p>The data structure contains labels and text. The training dataset contains 650,000 samples, while test dataset contains 50,000 samples.</p>
<h2 id="Tokenize"><a href="#Tokenize" class="headerlink" title="Tokenize"></a>Tokenize</h2><p>We need a tokenizer to convert the text into tokens used to train the model. We use <code>bert-base-uncased</code> as a tokenizer.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, BertTokenizerFast<br><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):<br>    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">&quot;text&quot;</span>], padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)<br><br>tokenized_datasets = dataset.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>We will no confuse the <code>examples[&quot;text&quot;]</code> when we are familiar with the data structure. The <code>map</code> method seems to batch tokenize data, with default batch size of 1000. <code>batched=True</code> means batching is enabled. So 650,000 data smaples will be divied into 650 batchs (650,000&#x2F;1000 &#x3D; 650). The <code>tokenize_function</code> will be called 650 times.</p>
<p>There are too much data to train and it will be very slow on my hardware. Thereforre, I will randomly select 1000 samples from both the trainning and test datasets.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">small_train_dataset = tokenized_datasets[<span class="hljs-string">&quot;train&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))<br>small_eval_dataset = tokenized_datasets[<span class="hljs-string">&quot;test&quot;</span>].shuffle(seed=<span class="hljs-number">42</span>).select(<span class="hljs-built_in">range</span>(<span class="hljs-number">1000</span>))<br></code></pre></td></tr></table></figure>

<p>If you are in debug model, you can see the differences bewteen <code>dataset</code> and <code>tokenized_datasets</code>. The <code>tokenized_datasets</code> contains additional fields such as <code>input_ids</code>, <code>token_type_ids</code> and <code>attention_mask</code>. Let’s delve deeper into what these fields are. Don’t be afraid; this is part of familiarizing yourself with the data.</p>
<p>I wrote a new code snippet to show what these fields are.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer<br><span class="hljs-comment"># Initialize the tokenizer</span><br>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)<br><br><span class="hljs-comment"># Define two sequences</span><br>sequence_1 = <span class="hljs-string">&quot;This is the first sentence.&quot;</span><br>sequence_2 = <span class="hljs-string">&quot;This is the second sentence.&quot;</span><br><br><span class="hljs-comment"># Tokenize the sequences</span><br>encoded_input = tokenizer(sequence_1, sequence_2, padding=<span class="hljs-string">&quot;max_length&quot;</span>, truncation=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># Print the tokenized output</span><br><span class="hljs-built_in">print</span>(encoded_input)<br><br><span class="hljs-comment"># Print the tokenized output</span><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Input IDs: &quot;</span>, encoded_input[<span class="hljs-string">&#x27;input_ids&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Token Type IDs: &quot;</span>, encoded_input[<span class="hljs-string">&#x27;token_type_ids&#x27;</span>])<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Attention Mask: &quot;</span>, encoded_input[<span class="hljs-string">&#x27;attention_mask&#x27;</span>])<br></code></pre></td></tr></table></figure>
<p>Output: </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span>&#x27;input_ids&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">101</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1188</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1110</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1103</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1148</span><span class="hljs-punctuation">,</span> <span class="hljs-number">5650</span><span class="hljs-punctuation">,</span> <span class="hljs-number">119</span><span class="hljs-punctuation">,</span> <span class="hljs-number">102</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1188</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1110</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1103</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1248</span><span class="hljs-punctuation">,</span> <span class="hljs-number">5650</span><span class="hljs-punctuation">,</span> <span class="hljs-number">119</span><span class="hljs-punctuation">,</span> <span class="hljs-number">102</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> &#x27;token_type_ids&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span> &#x27;attention_mask&#x27;<span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">&#125;</span><br>```css<br>Input IDs<span class="hljs-punctuation">:</span>  <span class="hljs-punctuation">[</span><span class="hljs-number">101</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1188</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1110</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1103</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1148</span><span class="hljs-punctuation">,</span> <span class="hljs-number">5650</span><span class="hljs-punctuation">,</span> <span class="hljs-number">119</span><span class="hljs-punctuation">,</span> <span class="hljs-number">102</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1188</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1110</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1103</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1248</span><span class="hljs-punctuation">,</span> <span class="hljs-number">5650</span><span class="hljs-punctuation">,</span> <span class="hljs-number">119</span><span class="hljs-punctuation">,</span> <span class="hljs-number">102</span><span class="hljs-punctuation">]</span><br>Token Type IDs<span class="hljs-punctuation">:</span>  <span class="hljs-punctuation">[</span><span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">]</span><br>Attention Mask<span class="hljs-punctuation">:</span>  <span class="hljs-punctuation">[</span><span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">,</span> <span class="hljs-number">1</span><span class="hljs-punctuation">]</span><br></code></pre></td></tr></table></figure>
<p>As you can see, the two sentences are tokenized into tokens. There are many <code>0</code>s, but I cut them off because they were too long to show.<br>Let’s compare the sentences and the input_ids, and you will see they corespond to each other. <code>101</code> is <code>[CLS]</code> and <code>119</code> is <code>[SEP]</code>. 102 is also<code>[SEP]</code>. The other numers represent the content of the sentences.</p>
<p>Special tokens are used to mark the beginning of a sentence. However, <code>token_types_ids</code> provide an additional explicit way to distinguish between sentences. While the <code>[CLS]</code> and <code>[SEP]</code> tokens help the model identify boundaries and structure, <code>token_type_ids</code> add another layer of clarity by explicitly indicating which tokens belong to which segment.</p>
<p>The <code>attenion_mask</code> is used to mask out the padding tokens. As I mentioned earlier,I cut off the padding tokens to show the essential parts.</p>
<h1 id="Train"><a href="#Train" class="headerlink" title="Train"></a>Train</h1><p>Ok, enoght explored the data. Let’s train the model!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments, Trainer<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> evaluate<br><br>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>, num_labels=<span class="hljs-number">5</span>)<br><br><span class="hljs-comment"># Create arguments for training</span><br>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;test_trainer&quot;</span>)<br>metric = evaluate.load(<span class="hljs-string">&quot;accuracy&quot;</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):<br>    logits, labels = eval_pred<br>    predictions = np.argmax(logits, axis=-<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)<br><br>trainer = Trainer(<br>    model=model,<br>    args=training_args,<br>    train_dataset=small_train_dataset,<br>    eval_dataset=small_eval_dataset,<br>    compute_metrics=compute_metrics,<br>)<br><br>trainer.train()<br><br><span class="hljs-comment"># Save the trained model</span><br>model_save_path = <span class="hljs-string">&quot;jc-test-fine-tuned&quot;</span><br>trainer.save_model(model_save_path)<br><br><span class="hljs-comment"># Save the tokenizer</span><br>tokenizer2 = BertTokenizerFast.from_pretrained(<span class="hljs-string">&#x27;google-bert/bert-base-cased&#x27;</span>)<br>tokenizer2.save_pretrained(model_save_path)<br></code></pre></td></tr></table></figure>
<p>It toke me about 3 minutes to train the model. My GPU is a P100.<br>Ouput:</p>
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs 1c"><span class="hljs-number">100</span>%<span class="hljs-string">|██████████| 375/375 [03:12&lt;00:00,  1.95it/s]</span><br>&#123;&#x27;train_runtime&#x27;: <span class="hljs-number">192.3716</span>, &#x27;train_samples_per_second&#x27;: <span class="hljs-number">15.595</span>, &#x27;train_steps_per_second&#x27;: <span class="hljs-number">1.949</span>, &#x27;train_loss&#x27;: <span class="hljs-number">0.98265625</span>, &#x27;epoch&#x27;: <span class="hljs-number">3.0</span>&#125;<br></code></pre></td></tr></table></figure>
<p>Honestly, I’m not very sure about the result.For example, the <code>train_loss</code> is 0.98265625, Is that good or bad? In my experience with pytorch, the loss in regression or classification demos is usually much lower, almost 0. However, I’m not familiar with the expectations for large language models(LLMs).</p>
<p>I’m documenting this as a record, ant his is alsl my first time writing in Enlgish.</p>
<h1 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline<br>unmasker = pipeline(<span class="hljs-string">&#x27;fill-mask&#x27;</span>, model=<span class="hljs-string">&#x27;jc-test-fine-tuned&#x27;</span>)<br>result = unmasker(<span class="hljs-string">&quot;My expectations for [MASK] are t rarely high.&quot;</span>)<br><span class="hljs-built_in">print</span>(result)<br></code></pre></td></tr></table></figure>
<p>Output:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs s">[&#123;&#x27;score&#x27;: 0.0024227965623140335, &#x27;token&#x27;: 24736, &#x27;token_str&#x27;: &#x27;Rashid&#x27;, &#x27;sequence&#x27;: &quot;Hello I&#x27;m a Rashid model.&quot;&#125;, &#123;&#x27;score&#x27;: 0.0018962057074531913, &#x27;token&#x27;: 24880, &#x27;token_str&#x27;: &#x27;Bose&#x27;, &#x27;sequence&#x27;: &quot;Hello I&#x27;m a Bose model.&quot;&#125;, &#123;&#x27;score&#x27;: 0.00178907613735646, &#x27;token&#x27;: 12416, &#x27;token_str&#x27;: &#x27;##iva&#x27;, &#x27;sequence&#x27;: &quot;Hello I&#x27;m aiva model.&quot;&#125;, &#123;&#x27;score&#x27;: 0.0013699078699573874, &#x27;token&#x27;: 18666, &#x27;token_str&#x27;: &#x27;boarded&#x27;, &#x27;sequence&#x27;: &quot;Hello I&#x27;m a boarded model.&quot;&#125;, &#123;&#x27;score&#x27;: 0.0013235692167654634, &#x27;token&#x27;: 21664, &#x27;token_str&#x27;: &#x27;##lett&#x27;, &#x27;sequence&#x27;: &quot;Hello I&#x27;m alett model.&quot;&#125;]<br><br></code></pre></td></tr></table></figure>
<p>This demonstrates the inference using the model we just trained. I don’t fully undenstand the output or its relation to the model, but it seems to be working well. This is the beginning of journey into learning machine learning and my english.</p>
<p>reference: <a target="_blank" rel="noopener" href="https://huggingface.co/docs/transformers/en/training">transformers</a></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Fine-Tuning a Pretrained Model - A Beginner&#39;s Journey</div>
      <div>https://jevoncode.github.io/2024/07/13/fine-tune-a-pretrained-model-with-transformers/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>Jevoncode</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>July 13, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/06/11/stay-true/" title="初心">
                        <span class="hidden-mobile">初心</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
